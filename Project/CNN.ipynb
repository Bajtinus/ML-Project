{
 "cells": [
  {
   "cell_type": "code",
   "id": "848cea1e7d1017b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T15:43:02.203575Z",
     "start_time": "2024-12-12T15:43:02.199485Z"
    }
   },
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "ROOT = pathlib.Path(\"D:\\\\ML_Dataset\")\n",
    "PATH = pathlib.Path(ROOT / \"processed\" / \"training\")\n",
    "TEST_PATH = pathlib.Path(\"D:\\\\ML_Dataset\\\\bite_size\\\\test\")\n",
    "SAMPLE_SIZE = 50"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T15:43:04.319650Z",
     "start_time": "2024-12-12T15:43:04.315456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_image(image_path):\n",
    "    # Load image with target size matching training input\n",
    "    image = load_img(image_path, target_size=(150, 150))\n",
    "\n",
    "    # Convert image to array\n",
    "    image_array = img_to_array(image)\n",
    "\n",
    "    # Expand dimensions to fit model input shape (batch size, height, width, channels)\n",
    "    image_array = np.expand_dims(image_array, axis=0)\n",
    "\n",
    "    # Normalize the image array as done during model training\n",
    "    image_array /= 255.0\n",
    "\n",
    "    return image_array"
   ],
   "id": "228c7fb69e8b5c29",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T15:43:06.167410Z",
     "start_time": "2024-12-12T15:43:06.163804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_image_class(image_path):\n",
    "    processed_image = preprocess_image(image_path)\n",
    "\n",
    "    # Predict the class of the image\n",
    "    prediction = model.predict(processed_image)\n",
    "\n",
    "    # Assuming the model is binary for simplicity, adjust as needed for multiclass\n",
    "    if prediction[0] > 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ],
   "id": "55020a8f1ce2d011",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T15:43:06.896764Z",
     "start_time": "2024-12-12T15:43:06.893783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i, path in enumerate(pathlib.Path(PATH).iterdir()):\n",
    "    if i == SAMPLE_SIZE:\n",
    "        break\n",
    "    print(path.name)"
   ],
   "id": "e4c39a5f421165af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actinotrocha\n",
      "amphipods\n",
      "appendicularia\n",
      "appendicularia_house\n",
      "bipinnaria\n",
      "blurry\n",
      "copepods\n",
      "diatoms\n",
      "echinodermata\n",
      "eggs\n",
      "larvae\n",
      "malacostraca\n",
      "medusae\n",
      "mnemiopsis\n",
      "noctiluca\n",
      "phaeocystis\n",
      "pilidium\n",
      "pluteus\n",
      "polychaeta\n",
      "pteropods\n",
      "rod\n",
      "snow\n",
      "unknown\n",
      "worms\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-12T15:43:11.333752Z",
     "start_time": "2024-12-12T15:43:07.723036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                   rotation_range=20,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(PATH,\n",
    "                                                    target_size=(150, 150),\n",
    "                                                    batch_size=SAMPLE_SIZE*5,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(PATH,\n",
    "                                                              target_size=(150, 150),\n",
    "                                                              batch_size=SAMPLE_SIZE*5,\n",
    "                                                              class_mode='binary')"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 124114 images belonging to 24 classes.\n",
      "Found 124114 images belonging to 24 classes.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T15:43:12.061735Z",
     "start_time": "2024-12-12T15:43:11.974864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n"
   ],
   "id": "2842665144dc09b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\filip\\PycharmProjects\\ML-Project\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T15:43:13.792765Z",
     "start_time": "2024-12-12T15:43:13.780145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ],
   "id": "7de6827ec7b40886",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T15:43:14.990397Z",
     "start_time": "2024-12-12T15:43:14.987669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ],
   "id": "2931d316b670a4c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1463691575305718188\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T15:43:18.017341Z",
     "start_time": "2024-12-12T15:43:18.010128Z"
    }
   },
   "cell_type": "code",
   "source": "tf.config.list_physical_devices('GPU')",
   "id": "5fa106efa955a678",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T15:43:18.546783Z",
     "start_time": "2024-12-12T15:43:18.543617Z"
    }
   },
   "cell_type": "code",
   "source": "tf.test.is_built_with_cuda()",
   "id": "38d7b2857c951b2f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-12-12T15:43:21.234677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    model.fit(train_generator,\n",
    "              steps_per_epoch=20,\n",
    "              epochs=5,\n",
    "              validation_data=validation_generator,\n",
    "              validation_steps=len(validation_generator))"
   ],
   "id": "8bb87955dc127184",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\filip\\PycharmProjects\\ML-Project\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001B[1m20/20\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2s/step - accuracy: 0.0018 - loss: -15633.4268"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\filip\\PycharmProjects\\ML-Project\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T15:36:11.005639800Z",
     "start_time": "2024-12-08T14:10:20.482116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_loss, test_accuracy = model.evaluate(validation_generator)\n",
    "print(f\"Test accuracy: {test_accuracy:.2f}\")"
   ],
   "id": "891f2cb40509b580",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2483/2483\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m178s\u001B[0m 72ms/step - accuracy: 0.0024 - loss: -4791260298169345376256.0000\n",
      "Test accuracy: 0.00\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T15:36:11.005639800Z",
     "start_time": "2024-12-08T14:13:27.671679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for pic in TEST_PATH.iterdir():\n",
    "    print(f\"{pic.name}: {predict_image_class(pic)}\")"
   ],
   "id": "a7b592c918b500ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step\n",
      "fs534_copepods_roi1.4031192200.tif.png: 1\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step\n",
      "fs534_copepods_roi1.4048441100.tif.png: 1\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step\n",
      "fs534_copepods_roi1.4133164900.tif.png: 1\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step\n",
      "fs534_copepods_roi1.4183715200.tif.png: 1\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step\n",
      "training_diatoms_roi0.4070788301.tif.png: 1\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step\n",
      "training_diatoms_roi0.4073816201.tif.png: 1\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step\n",
      "training_diatoms_roi2.4413740400.tif.png: 1\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step\n",
      "training_diatoms_roi2.4620018000.tif.png: 1\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step\n",
      "training_diatoms_roi3.4488066800.tif.png: 1\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step\n",
      "training_diatoms_roi3.4503847800.tif.png: 1\n"
     ]
    }
   ],
   "execution_count": 72
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
